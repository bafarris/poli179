{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evFxNFuBzLdM"
      },
      "source": [
        "Examining data from Cochrane, Christopher, et al. “The Automatic Analysis of Emotion in Political Speech Based on Transcripts.” Political Communication, vol. 39, no. 1, 2022, pp. 98–121, https://doi.org/10.1080/10584609.2021.1952497.\n",
        "\n",
        "Datasets loaded from here: https://github.com/ccochrane/emotionTranscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxw4PacoSs0D",
        "outputId": "5c950f51-ee53-4800-b7fa-4224d6ce413d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Dense, Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zosr-0o98ZwZ",
        "outputId": "5383a47d-bbe4-4678-8151-1f8ef1655277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0.1', 'Video', 't1Act1', 't1Act2', 't1ActAvg', 't1Sent1',\n",
            "       't1Sent2', 't1SentAvg', 't2Act1', 't2Act2', 't2ActAvg', 't2Sent1',\n",
            "       't2Sent2', 't2SentAvg', 't3Act1', 't3Act2', 't3ActAvg', 't3Sent1',\n",
            "       't3Sent2', 't3SentAvg', 'Unnamed: 0', 'v1Act1', 'v1Act2', 'v1ActAvg',\n",
            "       'v1Sent1', 'v1Sent2', 'v1SentAvg', 'v2Act1', 'v2Act2', 'v2ActAvg',\n",
            "       'v2Sent1', 'v2Sent2', 'v2SentAvg', 'v3Act1', 'v3Act2', 'v3ActAvg',\n",
            "       'v3Sent1', 'v3Sent2', 'v3SentAvg'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0.1         Video  t1Act1  t1Act2  t1ActAvg  t1Sent1  t1Sent2  \\\n",
            "0             0  2017 12 13 0       7       6       6.5        2        3   \n",
            "1             1  2017 12 13 1       6       6       6.0        4        4   \n",
            "2             2  2017 12 13 2       6       7       6.5        7        8   \n",
            "3             3  2017 12 13 3       7       8       7.5        0        0   \n",
            "4             4  2017 12 13 4       6       7       6.5        7        4   \n",
            "\n",
            "   t1SentAvg  t2Act1  t2Act2  ...  v2ActAvg  v2Sent1  v2Sent2  v2SentAvg  \\\n",
            "0        2.5     7.0       7  ...       8.0      2.0      2.0        2.0   \n",
            "1        4.0     5.0       5  ...       7.0      6.0      NaN        6.0   \n",
            "2        7.5     9.0       5  ...       8.0      8.0      NaN        8.0   \n",
            "3        0.0     7.0       7  ...       9.0      2.0      1.0        1.5   \n",
            "4        5.5     6.0       6  ...       NaN      NaN      NaN        NaN   \n",
            "\n",
            "   v3Act1  v3Act2  v3ActAvg  v3Sent1  v3Sent2  v3SentAvg  \n",
            "0     7.0     8.0       7.5      3.0      2.0        2.5  \n",
            "1     6.0     5.0       5.5      6.0      5.0        5.5  \n",
            "2     NaN     NaN       NaN      NaN      NaN        NaN  \n",
            "3     7.0     NaN       7.0      3.0      NaN        3.0  \n",
            "4    10.0     NaN      10.0      7.0      NaN        7.0  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ],
      "source": [
        "# load human coder sentiment scores dataset\n",
        "coding_decisions_df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/bafarris/speech-sentiment-bilstm/main/data/fullCodingData.csv',\n",
        "    sep=','\n",
        ")\n",
        "\n",
        "# examine\n",
        "print(coding_decisions_df.columns)\n",
        "print(coding_decisions_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osWAg1Drbdpi",
        "outputId": "4f398ea5-502f-4418-dfe4-4a66348e1169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   t1Sent1  t1Sent2  t1SentAvg  t2Sent1  t2Sent2  t2SentAvg  t3Sent1  t3Sent2  \\\n",
            "0        2        3        2.5      1.0        2        1.5      3.0      3.0   \n",
            "1        4        4        4.0      7.0        5        6.0      4.0      4.0   \n",
            "2        7        8        7.5      6.0        7        6.5      5.0      6.0   \n",
            "3        0        0        0.0      1.0        1        1.0      2.0      3.0   \n",
            "4        7        4        5.5      8.0        3        5.5      6.0      6.0   \n",
            "\n",
            "   t3SentAvg  \n",
            "0        3.0  \n",
            "1        4.0  \n",
            "2        5.5  \n",
            "3        2.5  \n",
            "4        6.0  \n"
          ]
        }
      ],
      "source": [
        "# filter columns to just text sentiment scores\n",
        "text_sentiment_columns = [col for col in coding_decisions_df.columns if col.startswith('t') and 'Sent' in col]\n",
        "text_sentiment_df = coding_decisions_df[text_sentiment_columns]\n",
        "\n",
        "# examine\n",
        "print(text_sentiment_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cdwpVMD-TB0",
        "outputId": "9790160b-16b1-4b1f-8498-4df31097bd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  parliamentNumber  parliamentSession orderOfBusinessRubric  \\\n",
            "0           0                39                  1                 Other   \n",
            "1           1                39                  1                 Other   \n",
            "2           2                39                  1                 Other   \n",
            "3           3                39                  1                 Other   \n",
            "4           4                39                  1                 Other   \n",
            "\n",
            "  subjectOfBusinessTitle  subjectOfBusinessID subjectOfBusinessQualifier  \\\n",
            "0                    NaN            1498168.0                        NaN   \n",
            "1    Election of Speaker            1498174.0                        NaN   \n",
            "2    Election of Speaker            1498174.0                        NaN   \n",
            "3    Election of Speaker            1498174.0                        NaN   \n",
            "4    Election of Speaker            1498174.0                        NaN   \n",
            "\n",
            "           speechId  interventionId           date  ... floorLanguage  \\\n",
            "0  2006-4-3-1498170         1498170  April 3, 2006  ...            FR   \n",
            "1  2006-4-3-1498123         1498123  April 3, 2006  ...            FR   \n",
            "2  2006-4-3-1498162         1498162  April 3, 2006  ...            EN   \n",
            "3  2006-4-3-1498163         1498163  April 3, 2006  ...            EN   \n",
            "4  2006-4-3-1498164         1498164  April 3, 2006  ...            EN   \n",
            "\n",
            "                                              speech  \\\n",
            "0  Pursuant to Standing Order 3, I invite Mr. Bla...   \n",
            "1  Thank you very much, dear colleagues. Welcome ...   \n",
            "2  I say welcome to our hon. colleagues, welcome ...   \n",
            "3   I will now call upon Mr. Peter Milliken, the ...   \n",
            "4  Mr. Chairman and hon. colleagues, I want to ex...   \n",
            "\n",
            "                                      speechFiltered  mentionedDocumentsTitle  \\\n",
            "0   Pursuant_JJ to_IN Standing_VBG Order_NN 3_CD ...                       []   \n",
            "1   Thank_VBP you_PRP very_RB much_RB ,_, dear_JJ...                       []   \n",
            "2   I_PRP say_VBP welcome_JJ to_IN our_PRP$ hon_N...                       []   \n",
            "3    _ I_PRP will_MD now_RB call_VB upon_IN Mr._N...                       []   \n",
            "4   Mr._NNP Chairman_NNP and_CC hon_NN ._. collea...                       []   \n",
            "\n",
            "  mentionedDocumentsId mentionedDocumentsType    mentionedEntityName  \\\n",
            "0                   []                     []  ['Elmwood—Transcona']   \n",
            "1                   []                     []            ['Sudbury']   \n",
            "2                   []                     []                     []   \n",
            "3                   []                     []                     []   \n",
            "4                   []                     []                     []   \n",
            "\n",
            "  mentionedEntityId  mentionedEntityType                  filename  \n",
            "0         ['78734']               ['NA']  Hansard\\HAN001-E39-1.XML  \n",
            "1         ['78383']               ['NA']  Hansard\\HAN001-E39-1.XML  \n",
            "2                []                   []  Hansard\\HAN001-E39-1.XML  \n",
            "3                []                   []  Hansard\\HAN001-E39-1.XML  \n",
            "4                []                   []  Hansard\\HAN001-E39-1.XML  \n",
            "\n",
            "[5 rows x 47 columns]\n",
            "1314.084397233906\n",
            "Number of rows: 350675\n",
            "Number of columns: 47\n"
          ]
        }
      ],
      "source": [
        "# load corpus of text data frame\n",
        "\n",
        "# dropbox shared link\n",
        "dropbox_link = \"https://www.dropbox.com/s/4xzw3rscu7x7xn3/hansardExtractedSpeechesFull.csv.zip?dl=1\"\n",
        "\n",
        "# send a get request to download the file\n",
        "response = requests.get(dropbox_link)\n",
        "\n",
        "# get content from zipfile\n",
        "with ZipFile(BytesIO(response.content)) as zipfile:\n",
        "    file_name = zipfile.namelist()[0]\n",
        "    # read csv\n",
        "    with zipfile.open(file_name) as file:\n",
        "        corpus_df = pd.read_csv(file, delimiter='\\t')\n",
        "\n",
        "# examine corpus_df\n",
        "print(corpus_df.head())\n",
        "\n",
        "# calculate the average length of the text in the 'speech' column\n",
        "average_length = corpus_df['speech'].fillna('').apply(len).mean()\n",
        "print(average_length)\n",
        "\n",
        "# number of rows and columns\n",
        "print(\"Number of rows:\", corpus_df.shape[0])\n",
        "print(\"Number of columns:\", corpus_df.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORK IN PROGRESS!!!"
      ],
      "metadata": {
        "id": "MC7rBIddAwPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qIHUfhbT0S00"
      },
      "outputs": [],
      "source": [
        "# pre-process corpus data\n",
        "\n",
        "# define preprocessing\n",
        "def preprocess_text(text):\n",
        "    # tokenize\n",
        "    words = word_tokenize(text.lower())\n",
        "    # remove stop words\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords.words('english')]\n",
        "    return words\n",
        "\n",
        "# apply preprocessing to 'speech' column\n",
        "corpus_df['tokens'] = corpus_df['speech'].fillna('').apply(preprocess_text)\n",
        "\n",
        "# prepare sentences for word2vec\n",
        "sentences = corpus_df['tokens'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKIhvhHH26Fh"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "word2vec_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=300,  # 300 dimensions\n",
        "    window=6,         # 6-word window\n",
        "    min_count=10,      # 10 min word count\n",
        "    epochs=5          # 5 iterations\n",
        ")\n",
        "\n",
        "# save model\n",
        "word2vec_model.save(\"word2vec.model\")\n",
        "\n",
        "# check model\n",
        "print(word2vec_model.wv.key_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWd9ldDEvl9p"
      },
      "outputs": [],
      "source": [
        "# check to see if number of tokens and words in vocabulary is similar to other researchers after pre-processing\n",
        "\n",
        "# single list tokens\n",
        "all_tokens = [token for sublist in corpus_df['tokens'].tolist() for token in sublist]\n",
        "\n",
        "# number of tokens\n",
        "number_of_tokens = len(all_tokens)\n",
        "print(\"Number of tokens:\", number_of_tokens)\n",
        "\n",
        "# number of unique words in vocabulary\n",
        "unique_words = set(all_tokens)\n",
        "vocabulary_size = len(unique_words)\n",
        "print(\"Number of unique words:\", vocabulary_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbwjguyQ6-Eu"
      },
      "source": [
        "After Pre-Processing:\n",
        "\n",
        "Number of tokens: 37,829,396\n",
        "\n",
        "Number of unique words: 93,475\n",
        "\n",
        "Original research:\n",
        "\n",
        "Number of tokens: 49,713,429\n",
        "\n",
        "Number of unique words: 40,597"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKQSP21Zf0GX"
      },
      "outputs": [],
      "source": [
        "# initalize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "### trying different ideas so i don't run out of RAM?????\n",
        "# incrementally fit tokenizer\n",
        "batch_size = 10000\n",
        "for i in range(0, len(corpus_df), batch_size):\n",
        "    batch_texts = corpus_df['tokens'][i:min(i+batch_size, len(corpus_df))].apply(lambda x: ' '.join(x)).tolist()\n",
        "    tokenizer.fit_on_texts(batch_texts)\n",
        "\n",
        "# convert tokens to sequences\n",
        "corpus_df['sequences'] = corpus_df['tokens'].apply(lambda x: ' '.join(x))\n",
        "sequences = tokenizer.texts_to_sequences(corpus_df['sequences'].tolist())\n",
        "\n",
        "# pad sequences\n",
        "X = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "# NEED TO PUT IN SENTIMENT COLUMNS\n",
        "y = text_sentiment_df['INSERT_SENTIMENT_COLUMNS'].values\n",
        "\n",
        "# split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# define bi-lstm\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# generator: feed data to model in batches\n",
        "def data_generator(X_data, y_data, batch_size):\n",
        "    total_samples = len(X_data)\n",
        "    while True:\n",
        "        for start in range(0, total_samples, batch_size):\n",
        "            end = min(start + batch_size, total_samples)\n",
        "            yield X_data[start:end], y_data[start:end]\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, 64)\n",
        "val_gen = data_generator(X_test, y_test, 64)\n",
        "\n",
        "# train model using generator\n",
        "model.fit(train_gen, steps_per_epoch=len(X_train)//64, epochs=10, validation_data=val_gen, validation_steps=len(X_test)//64)\n",
        "\n",
        "# evaluate\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}